{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify local path of the CZO dataset table\n",
    "df1 = pd.read_csv(\"/home/christian/Downloads/czo-datasets-metadata-2018-02-02.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = df1['COMPONENT_FILES-location$topic$url$data_level$private$doi$metadata_url']\n",
    "componentFiles = []\n",
    "for i in range(0,len(comp)):\n",
    "    row = comp[i].split('|')\n",
    "    for j in range(0, len(row)):\n",
    "        componentFiles.append(row[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "urls1 = []\n",
    "urls2 = []\n",
    "for c in componentFiles:\n",
    "    a,b,url1,d,e,f,url2 = c.split(\"$\")\n",
    "    urls1.append(url1)\n",
    "    urls2.append(url2)\n",
    "\n",
    "urls = urls1+urls2\n",
    "ext1 = []\n",
    "for u in urls2:\n",
    "    ext1.append(u.rsplit(\".\",1)[-1])\n",
    "    \n",
    "ext2 = []\n",
    "for e in ext1:\n",
    "    ext2.append((e.split('/', 1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "seen=set()\n",
    "count = 0\n",
    "\n",
    "for i in range(len(ext2)):\n",
    "    word = ext2[i]\n",
    "    if word not in seen:\n",
    "        seen.add(word)\n",
    "        \n",
    "        for j in range(len(ext2)):\n",
    "            a_duplicate = ext2[j]\n",
    "            if (word == a_duplicate):\n",
    "                count += 1   \n",
    "                \n",
    "        d[word] = count\n",
    "        count =0\n",
    "\n",
    "ext_sorted = sorted(d.items(), key=lambda x: (-x[1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 807),\n",
       " ('hdr', 641),\n",
       " ('docx', 220),\n",
       " ('csv', 116),\n",
       " ('txt', 61),\n",
       " ('pdf', 12),\n",
       " ('org', 4),\n",
       " ('1&format=xml', 1),\n",
       " ('aspx?n=158', 1),\n",
       " ('aspx?n=159', 1),\n",
       " ('aspx?n=160', 1),\n",
       " ('aspx?n=161', 1),\n",
       " ('aspx?n=162', 1),\n",
       " ('aspx?n=163', 1),\n",
       " ('aspx?n=177', 1),\n",
       " ('xlsx', 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this to create a txt file and store the list\n",
    "with open('COMPONENT_FILES_$metadata_url.txt', 'w') as fp:\n",
    "    fp.write('\\n'.join('%s %s' % x for x in ext_sorted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
